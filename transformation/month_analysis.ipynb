{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering data and getting stats on a specific month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "import datetime\n",
    "from collections import Counter\n",
    "from  itertools import chain\n",
    "\n",
    "from textblob import Blobber\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = 'france'\n",
    "month = 9\n",
    "year = 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 204240 comments\n",
      "We have 11286 posts\n"
     ]
    }
   ],
   "source": [
    "comments = pd.read_parquet('exports/' + subreddit + '/' + subreddit + '_comments_merged.parquet', engine='pyarrow')\n",
    "assert len(comments[comments.duplicated(['comment_id'])]) == 0, \"Meh, I found some duplicated comments IDs in the dataframe\"\n",
    "\n",
    "posts = pd.read_parquet('exports/' + subreddit + '/' + subreddit + '_posts_merged.parquet', engine='pyarrow')\n",
    "assert len(posts[posts.duplicated(['post_id'])]) == 0, \"Meh, I found some duplicated post IDs in the dataframe\"\n",
    "\n",
    "print('We have ' + str(len(comments)) + ' comments')\n",
    "print('We have ' + str(len(posts)) + ' posts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering on comments published in the specific month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 106720 comments\n",
      "We have 6927 posts\n"
     ]
    }
   ],
   "source": [
    "comments = comments[(comments['year_comment'] == year)\n",
    "    & (comments['month_comment'] == month)]\n",
    "posts = posts[(posts['year_post'] == year)\n",
    "    & (posts['month_post'] == month)]\n",
    "print('We have ' + str(len(comments)) + ' comments')\n",
    "print('We have ' + str(len(posts)) + ' posts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global\n",
    "### Number of posts\n",
    "### Number of comments\n",
    "### Top 3 posts with the highest number of comments (+ links)\n",
    "### Average number of comments per posts\n",
    "### Number of unique authors (posts + comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_posts = posts['post_id'].nunique()\n",
    "nb_comments = comments['comment_id'].nunique()\n",
    "top_com1 = posts.nlargest(3,'nb_comment').iloc[:1]\n",
    "top_com2 = posts.nlargest(3,'nb_comment').iloc[1:2]\n",
    "top_com3 = posts.nlargest(3,'nb_comment').iloc[2:3]\n",
    "avg_comments_posts = round(posts['nb_comment'].mean(), 2)\n",
    "nb_active_users = np.unique(comments['author_post'] + comments['author_comment']).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language\n",
    "### Top 3 words appearing the most in titles\n",
    "### Top 3 words appearing the most in comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "france    320\n",
       "pas       212\n",
       "queen     185\n",
       "«         181\n",
       "plus      179\n",
       "»         170\n",
       "new       133\n",
       "|         130\n",
       "ne        127\n",
       "best      121\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_titles_words = pd.Series(' '.join(posts['title_processed']).split()).value_counts()[:10]\n",
    "top_titles_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pas      70674\n",
       "c'est    48364\n",
       "ne       28210\n",
       "plus     26680\n",
       "bien     13778\n",
       "faire    13639\n",
       "j'ai     12402\n",
       "qu'il     8162\n",
       "non       7793\n",
       "c’est     6855\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_comments_words = pd.Series(' '.join(comments['text_processed']).split()).value_counts()[:10]\n",
    "top_comments_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flairs\n",
    "### Number of posts per flair\n",
    "### Posts with the highest number of comments per flair (linked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_posts_flairs = posts.groupby(['flair']).size().sort_values(ascending=False)[:3].reset_index()\n",
    "biggest_post_flair1 = posts[posts['flair'] == nb_posts_flairs['flair'][0]].nlargest(1,'nb_comment')\n",
    "biggest_post_flair2 = posts[posts['flair'] == nb_posts_flairs['flair'][1]].nlargest(1,'nb_comment')\n",
    "biggest_post_flair3 = posts[posts['flair'] == nb_posts_flairs['flair'][2]].nlargest(1,'nb_comment')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('reddit_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "211f0b0304102da3630068b06045e4e4a78ffa0a6c596be87323c896afe13624"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
